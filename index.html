<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="AutoCoralMatch: An Open-Source Foundation Model-Driven Framework for Patch-Level Coral Health Assessment and Automated Bleaching Detection">
  <meta property="og:title" content="AutoCoralMatch: An Open-Source Foundation Model-Driven Framework for Patch-Level Coral Health Assessment and Automated Bleaching Detection"/>
  <meta property="og:description" content="AutoCoralMatch: An Open-Source Foundation Model-Driven Framework for Patch-Level Coral Health Assessment and Automated Bleaching Detection."/>
  <meta property="og:image" content="static/images/GFN (1).png" />   <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>AutoCoralMatch: Automated Coral Health Assessment</title>   <link rel="icon" type="image/x-icon" href="static/images/78357759.jpg">     <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>

  <style>
    /* Prevents unwanted word wrapping on section titles */
    h2.title {
      display: inline-block;
      text-align: center;
      white-space: nowrap;
      word-break: normal;
      overflow-wrap: break-word;
    }

    /* Ensures paragraphs do not break into vertical letters */
    .content p {
      text-align: justify;
      word-wrap: break-word;
      overflow-wrap: break-word;
    }

    /* Ensures titles and text stay in a horizontal layout */
    .column {
      padding: 15px;
      display: flex;
      justify-content: center;
      align-items: center;
    }

    /* Limits container width to prevent excessive wrapping */
    .container.is-max-desktop {
      max-width: 1100px;
    }

    /* Carousel Styling */
    .carousel {
      width: 100%;
      max-width: 900px;
      margin: auto;
    }

    .carousel img {
      width: 100%;
      height: auto;
      border-radius: 10px;
    }
    /* New styling for video containers to manage width */
    .video-container {
        width: 100%; /* Take full width of parent column */
        max-width: 600px; /* Adjust as needed for layout */
        margin: 0 auto; /* Center video */
    }
    .video-container video {
        width: 100%;
        height: auto;
        border-radius: 10px;
    }
  </style>
</head>

<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop has-text-centered">
      <h1 class="title is-1">AutoCoralMatch: An Open-Source Foundation Model-Driven Framework for Patch-Level Coral Health Assessment and Automated Bleaching Detection</h1>
      <p class="is-size-5">Lyes Saad Saoud and Irfan Hussain</p>
      <p class="is-size-5">Khalifa University Center for Autonomous Robotic Systems<br>Khalifa University, Abu Dhabi, United Arab Emirates</p>
    <p class="is-size-5">Preprint 2025</p>

      <div class="buttons is-centered">
        <a href="https://arxiv.org/pdf/<ARXIV_PAPER_ID>.pdf" class="button is-dark is-rounded">
          <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper</span>
        </a>
        <a href="https://github.com/LyesSaadSaoud/AI-CoralHealth" class="button is-dark is-rounded">
          <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
        </a>
        <a href="https://github.com/LyesSaadSaoud/AI-CoralHealth" class="button is-dark is-rounded">
          <span class="icon"><i class="fab fa-github"></i></span><span>Datasets</span>
        </a>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img src="static/images/main_figure.png" alt="AutoCoralMatch system illustration" style="width: 70%; border-radius: 10px;">
      <h2 class="subtitle">
        \textbf{Overview of the AutoCoralMatch system.} A modular, offline desktop application for coral health assessment using CoralWatch cards.
        \textbf{Left:} The user interface includes upload, dehazing, card detection, segmentation, rectification, coral-only extraction, and report generation (CSV/PDF). A built-in annotation tool enables patch-level labeling.
        \textbf{Middle:} Intermediate outputs from each pipeline stage, including isolated CoralWatch cards, the margin region, and coral-only imagery.
        \textbf{Right:} Key computational steps: (1) RAUNE-Net dehazing, (2) Grounding DINO detection, (3) SAM2 segmentation, (4) perspective rectification, (5) \textbf{YOLOv8} patch detection, (6) \textbf{HSV extraction}, (7) \textbf{HSV-based} health estimation, and (8) structured output.
        All components are GPU-accelerated, locally executable, and modularly designed.
      </h2>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Abstract</h2>
    <div class="content has-text-justified">
      <p>Coral reefs are highly sensitive indicators of climate change, making accurate and scalable monitoring tools critical for global conservation. Traditional CoralWatch-based assessments rely on manual diver observations and post-hoc color matching, which are labor-intensive, subjective, and difficult to scale.</p>
      <p>We present AutoCoralMatch, an open-source, modular software framework for automated coral health assessment from underwater imagery. The system integrates underwater image dehazing (RAUNE-Net), CoralWatch card detection using foundation vision models (Grounding DINO and SAM2), perspective rectification, patch-level color extraction, and health classification based on \textbf{perceptual color metrics in HSV space}. The software includes a user-friendly desktop interface supporting batch processing, real-time feedback, report generation, and structured metadata logging.</p>
      <p>To validate system performance, we conducted controlled marine trials with over 20 coral morphologies under varying lighting and turbidity. Results demonstrate robust card detection, geometric alignment, and consistent patch scoring across conditions. The platform reduces human bias, eliminates the need for diver-based annotation, and enables repeatable, low-cost, and AI-assisted reef monitoring workflows.</p>
      <p>AutoCoralMatch addresses key needs in environmental modeling and software: transparent algorithmic design, generalizability across reef environments, and reproducibility through publicly available code, pretrained models, and datasets. It supports long-term coral health modeling and can be integrated into decision-support systems for marine conservation.</p>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Before and After Dehazing (RAUNE-Net)</h2>
    <div class="columns is-multiline">
            <div class="column">
        <div class="slider-container">
          <div class="juxtapose uniform-slider" data-startingposition="50%">
            <img src="static/images/before1.jpg" alt="Before Dehazing" data-label="Before">
            <img src="static/images/after11.jpg" alt="After Dehazing" data-label="After">
          </div>
        </div>
      </div>

            <div class="column">
        <div class="slider-container">
          <div class="juxtapose uniform-slider" data-startingposition="50%">
            <img src="static/images/before2.jpg" alt="Before Dehazing" data-label="Before">
            <img src="static/images/after22.jpg" alt="After Dehazing" data-label="After">
          </div>
        </div>
      </div>

            <div class="column">
        <div class="slider-container">
          <div class="juxtapose uniform-slider" data-startingposition="50%">
            <img src="static/images/before3.jpg" alt="Before Dehazing" data-label="Before">
            <img src="static/images/after33.jpg" alt="After Dehazing" data-label="After">
          </div>
        </div>
      </div>

            <div class="column">
        <div class="slider-container">
          <div class="juxtapose uniform-slider" data-startingposition="50%">
            <img src="static/images/before4.jpg" alt="Before Dehazing" data-label="Before">
            <img src="static/images/after44.jpg" alt="After Dehazing" data-label="After">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css">
<script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script>


<section class="section hero is-light">
    <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">System Demonstrations</h2>
        <div class="columns is-centered">
            <div class="column is-half has-text-centered video-container">
                <video controls>
                    <source src="static/videos/video1.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p>Figure X: Demonstration of the AutoCoralMatch Desktop Application (Main Processing Pipeline).</p>
            </div>

            <div class="column is-half has-text-centered video-container">
                <video controls>
                    <source src="static/videos/video22.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <p>Figure Y: Demonstration of the CoralWatch Chart Annotation Tool (Data Preparation & Training).</p>
            </div>
        </div>
    </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">

                <div class="item">
          <div style="display: flex; justify-content: center; align-items: center; flex-direction: column; text-align: center;">
            <img src="static/images/Prop_dataset_synthetic.png" alt="Proposed dataset synthetic examples" style="max-width: 80%; height: auto; border-radius: 10px;">
            <h2 class="subtitle has-text-centered">
              <strong>Figure 5:</strong> Comparison of selected ground-truth (GT) coral images (top rows) and their corresponding synthetic hazy counterparts (bottom rows) from the proposed dataset.
            </h2>
          </div>
        </div>

                <div class="item">
          <div style="display: flex; justify-content: center; align-items: center; flex-direction: column; text-align: center;">
            <img src="static/images/GPT-detection.png" alt="GPT-4o and Manual Coral Classification" style="max-width: 80%; height: auto; border-radius: 10px;">
            <h2 class="subtitle has-text-centered">
              <strong>Figure 6:</strong> Comparison of GPT-4o and Manual Coral Classification.             </h2>
          </div>
        </div>

                <div class="item">
          <div style="display: flex; justify-content: center; align-items: center; flex-direction: column; text-align: center;">
            <img src="static/images/Fig5.png" alt="Impact of haze and dehazing models on coral detection quality" style="max-width: 80%; height: auto; border-radius: 10px;">
            <h2 class="subtitle has-text-centered">
              <strong>Figure 5:</strong> Impact of haze and dehazing models on coral detection quality. The first raw represents the ground truth (GT), followed by the hazy input images. The remaining columns show the results after applying different dehazing models. This comparison highlights the variation in detection quality depending on the enhancement method used.             </h2>
          </div>
        </div>

                <div class="item">
          <div style="display: flex; justify-content: center; align-items: center; flex-direction: column; text-align: center;">
            <img src="static/images/Fig6.png" alt="Visualization of input images, segmentation masks, and overlay results" style="max-width: 80%; height: auto; border-radius: 10px;">
            <h2 class="subtitle has-text-centered">
              <strong>Figure 6:</strong> Visualization of input images, segmentation masks, and overlay results. The first row represents the original input images, the second row shows the corresponding segmentation masks, and the third row presents the overlay of the masks on the original images.
            </h2>
        </div>

      </div>
    </div>
  </div>
</section>
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@article{AI-CoralWatch,
  author = {Saad Saoud, Lyes et al.},
  title = {AI-Powered Coral Watch: Pattern Recognition for Automated Bleaching Detection},
  year = {2025},
  publisher = {Preprint},
  doi = {......},
  url = {https://arxiv.org/...}}
</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <p>This page provides supplementary materials for "<strong>AutoCoralMatch: An Open-Source Foundation Model-Driven Framework for Patch-Level Coral Health Assessment and Automated Bleaching Detection</strong>." Access the paper, dataset, and code repository for more details.</p>
  </div>
</footer>

</body>
</html>
